import pickle

import pandas as pd
import pytest
from mongoengine import connect
from mongoengine.connection import disconnect
from mongoengine.errors import ValidationError
from pandas.testing import assert_frame_equal
from pymongo import MongoClient
from pyreal import RealApp

from sibyl.db import preprocessing, schema
from tests.conftest import test_database_name, test_host, test_port

# Generated by CodiumAI


@pytest.fixture(autouse=True)
def empty_database():
    client = MongoClient(test_host, test_port)
    client.drop_database(test_database_name)
    connect(test_database_name, host=test_host, port=test_port)

    yield client

    client.drop_database(test_database_name)
    disconnect()


class TestInsertFeaturesFromDataframe:
    #  Insert features with required columns only
    def test_insert_required_columns_only(self):
        # Create a dataframe with only the required columns
        features_df = pd.DataFrame({
            "name": ["feature1", "feature2", "feature3"],
            "type": ["numeric", "categorical", "boolean"],
        })

        # Call the function under test
        result = preprocessing.insert_features_from_dataframe(features_df)

        # Assert that the result is a list of the inserted feature names
        assert result == ["feature1", "feature2", "feature3"]

        # Assert that the features were inserted into the database correctly
        inserted_features = schema.Feature.find(as_df_=True)
        assert len(inserted_features) == 3
        assert set(inserted_features["name"]) == {"feature1", "feature2", "feature3"}
        assert set(inserted_features["type"]) == {"numeric", "categorical", "boolean"}

    #  Insert features with optional columns
    def test_insert_optional_columns(self):
        # Create a dataframe with required and optional columns
        features_df = pd.DataFrame({
            "name": ["feature1", "feature2", "feature3"],
            "type": ["numeric", "categorical", "boolean"],
            "description": ["Description 1", "Description 2", "Description 3"],
            "negated_description": [
                "Negated Description 1",
                "Negated Description 2",
                "Negated Description 3",
            ],
            "category": ["Category 1", "Category 2", "Category 3"],
            "values": [None, ["A", "B"], None],
        })

        # Call the function under test
        result = preprocessing.insert_features_from_dataframe(features_df)

        # Assert that the result is a list of the inserted feature names
        assert result == ["feature1", "feature2", "feature3"]

        # Assert that the features were inserted into the database correctly
        inserted_features = schema.Feature.find(as_df_=True)
        assert len(inserted_features) == 3
        assert set(inserted_features["name"]) == {"feature1", "feature2", "feature3"}
        assert set(inserted_features["type"]) == {"numeric", "categorical", "boolean"}
        assert set(inserted_features["description"]) == {
            "Description 1",
            "Description 2",
            "Description 3",
        }
        assert set(inserted_features["negated_description"]) == {
            "Negated Description 1",
            "Negated Description 2",
            "Negated Description 3",
        }
        assert set(inserted_features["category"]) == {"Category 1", "Category 2", "Category 3"}
        assert inserted_features.iloc[1, :]["values"] == ["A", "B"]

    #  Insert empty dataframe
    def test_insert_empty_dataframe(self):
        # Create an empty dataframe
        features_df = pd.DataFrame(columns=["name", "type"])

        # Call the function under test
        result = preprocessing.insert_features_from_dataframe(features_df)

        # Assert that the result is an empty list
        assert result == []

        # Assert that no features were inserted into the database
        inserted_features = schema.Feature.find(as_df_=True)
        assert len(inserted_features) == 0

    #  Insert dataframe with missing required columns
    def test_insert_missing_required_columns(self):
        # Create a dataframe with missing required columns
        features_df = pd.DataFrame({"name": ["feature1", "feature2", "feature3"]})

        # Call the function under test and expect a ValueError to be raised
        with pytest.raises(ValidationError):
            preprocessing.insert_features_from_dataframe(features_df)

        # Assert that no features were inserted into the database
        inserted_features = schema.Feature.find(as_df_=True)
        assert len(inserted_features) == 0

    #  Insert dataframe with invalid type
    def test_insert_invalid_type(self):
        # Create a dataframe with an invalid type
        features_df = pd.DataFrame({
            "name": ["feature1", "feature2", "feature3"],
            "type": ["numeric", "categorical", "invalid"],
        })

        # Call the function under test and expect a ValueError to be raised
        with pytest.raises(ValidationError):
            preprocessing.insert_features_from_dataframe(features_df)

        # Assert that no features were inserted into the database
        inserted_features = schema.Feature.find(as_df_=True)
        assert len(inserted_features) == 0


class TestInsertCategoriesFromDataframe:
    #  Insert categories with required columns only
    def test_insert_categories_required_columns_only(self):
        # Create a sample dataframe with required columns only
        category_df = pd.DataFrame({"name": ["Category1", "Category2", "Category3"]})

        # Call the function under test
        result = preprocessing.insert_categories_from_dataframe(category_df)

        # Assert that the categories were inserted correctly
        assert result == ["Category1", "Category2", "Category3"]

        inserted_categories = schema.Category.find(as_df_=True)
        assert len(inserted_categories) == 3
        assert set(inserted_categories["name"]) == {"Category1", "Category2", "Category3"}

    #  Insert categories with optional columns
    def test_insert_categories_optional_columns(self):
        # Create a sample dataframe with optional columns
        category_df = pd.DataFrame({
            "name": ["Category1", "Category2", "Category3"],
            "color": ["red", "blue", "green"],
            "abbreviation": ["C1", "C2", "C3"],
        })

        # Call the function under test
        result = preprocessing.insert_categories_from_dataframe(category_df)

        # Assert that the categories were inserted correctly
        assert result == ["Category1", "Category2", "Category3"]
        inserted_categories = schema.Category.find(as_df_=True)
        assert len(inserted_categories) == 3
        assert set(inserted_categories["name"]) == {"Category1", "Category2", "Category3"}
        assert set(inserted_categories["color"]) == {"red", "blue", "green"}
        assert set(inserted_categories["abbreviation"]) == {"C1", "C2", "C3"}

    #  Insert empty dataframe
    def test_insert_empty_dataframe(self):
        # Create an empty dataframe
        category_df = pd.DataFrame(columns=["name", "color", "abbreviation"])

        # Call the function under test
        result = preprocessing.insert_categories_from_dataframe(category_df)

        # Assert that no categories were inserted
        assert result == []
        inserted_categories = schema.Category.find(as_df_=True)
        assert (len(inserted_categories)) == 0

    #  Insert dataframe with missing required columns
    def test_insert_missing_required_columns(self):
        # Create a sample dataframe with missing required columns
        category_df = pd.DataFrame({"color": ["red", "blue", "green"]})

        # Call the function under test and expect a ValueError
        with pytest.raises(ValueError):
            preprocessing.insert_categories_from_dataframe(category_df)


class TestInsertContextFromDict:
    #  Insert a valid context dictionary and verify that it is inserted into the database.
    def test_valid_context_dictionary_inserted(self):
        # Arrange
        context_dict = {"context_config_key": "context_config_value"}

        # Act
        preprocessing.insert_context_from_dict(context_dict)

        # Assert
        context = schema.Context.find()[0].to_mongo()
        assert context["config"]["context_config_key"] == "context_config_value"


class TestInsertEntitiesFromDataframe:
    #  Insert entities with required columns and no labels
    def test_insert_entities_no_labels(self):
        # Create a sample dataframe with required columns and no labels
        entity_df = pd.DataFrame(
            {"eid": ["1", "2", "3"], "feature1": [0.1, 0.2, 0.3], "feature2": [0.4, 0.5, 0.6]}
        )

        # Call the function under test
        eids = preprocessing.insert_entities_from_dataframe(entity_df)

        # Assert that the eids returned match the expected values
        assert eids == ["1", "2", "3"]

        # Check that the database has the inserted entities
        inserted_entities = schema.Entity.find(as_df_=True)

        assert inserted_entities.shape[0] == len(eids)
        assert set(inserted_entities["eid"]) == set(eids)

    #  Insert entities with required columns and labels
    def test_insert_entities_with_labels(self):
        # Create a sample dataframe with required columns and labels
        entity_df = pd.DataFrame({
            "eid": ["1", "2", "3"],
            "feature1": [0.1, 0.2, 0.3],
            "feature2": [0.4, 0.5, 0.6],
            "label_col": [1, 0, 1],
        })

        # Call the function under test
        eids = preprocessing.insert_entities_from_dataframe(entity_df, label_column="label_col")

        # Assert that the eids returned match the expected values
        assert eids == ["1", "2", "3"]

        # Assert that the database has the inserted entities
        inserted_entities = schema.Entity.find(eid__in=eids)
        assert len(inserted_entities) == len(eids)
        for entity in inserted_entities:
            entity = entity.to_mongo()
            assert entity["eid"] in eids
            assert list(entity["labels"].values())[0] in [0, 1]
            assert list(entity["features"].values())[0]["feature1"] in [0.1, 0.2, 0.3]
            assert list(entity["features"].values())[0]["feature2"] in [0.4, 0.5, 0.6]

    #  Insert entities with optional row_id column
    def test_insert_entities_with_row_id(self):
        # Create a sample dataframe with required columns, labels, and row_id
        entity_df = pd.DataFrame({
            "eid": [1, 2],
            "feature1": [0.1, 0.2],
            "feature2": [0.4, 0.5],
            "row_id": [10, 20],
        })

        # Call the function under test
        eids = preprocessing.insert_entities_from_dataframe(entity_df)

        # Assert that the eids returned match the expected values
        assert eids == [1, 2]

        # Assert that the database has the correct entities
        inserted_entities = schema.Entity.find()
        assert len(inserted_entities) == 2
        assert inserted_entities[0].to_mongo()["eid"] == "1"
        assert inserted_entities[0].to_mongo()["row_ids"] == ["10"]
        assert inserted_entities[0].to_mongo()["features"] == {
            "10": {"feature1": 0.1, "feature2": 0.4}
        }
        assert inserted_entities[0].to_mongo()["labels"] == {}
        assert inserted_entities[1].to_mongo()["eid"] == "2"
        assert inserted_entities[1].to_mongo()["row_ids"] == ["20"]
        assert inserted_entities[1].to_mongo()["features"] == {
            "20": {"feature1": 0.2, "feature2": 0.5}
        }
        assert inserted_entities[1].to_mongo()["labels"] == {}

    #  Raise error if dataframe is empty
    def test_insert_entities_empty_dataframe(self):
        # Create an empty dataframe
        entity_df = pd.DataFrame()

        # Call the function under test and assert that it raises a FileNotFoundError
        assert len(preprocessing.insert_entities_from_dataframe(entity_df)) == 0

    #  Raise error if eid column is missing
    def test_insert_entities_missing_eid_column(self):
        # Create a sample dataframe without the eid column
        entity_df = pd.DataFrame({"feature1": [0.1, 0.2, 0.3], "feature2": [0.4, 0.5, 0.6]})

        with pytest.raises(ValueError):
            preprocessing.insert_entities_from_dataframe(entity_df)

    #  Raise error if feature columns are missing
    def test_insert_entities_missing_feature_columns(self):
        # Create a sample dataframe without the feature columns
        entity_df = pd.DataFrame({"eid": [1, 2, 3]})

        with pytest.raises(ValueError):
            preprocessing.insert_entities_from_dataframe(entity_df)

    #  Insert entities with maximum number of entities specified
    def test_insert_entities_max_entities_specified(self):
        # Create a sample dataframe with required columns and labels
        entity_df = pd.DataFrame({
            "eid": ["1", "2", "3", "4", "5"],
            "feature1": [0.1, 0.2, 0.3, 0.4, 0.5],
            "feature2": [0.4, 0.5, 0.6, 0.7, 0.8],
            "label": [1, 0, 1, 0, 1],
        })

        # Call the function under test with max_entities specified
        eids = preprocessing.insert_entities_from_dataframe(entity_df, max_entities=3)

        # Assert that the eids returned match the expected values
        assert len(eids) == 3
        assert len(schema.Entity.objects) == 3

    #  Insert entities with maximum number of entities greater than number of entities in dataframe
    def test_insert_entities_max_entities_greater_than_dataframe(self):
        # Create a sample dataframe with required columns and labels
        entity_df = pd.DataFrame({
            "eid": [1, 2, 3],
            "feature1": [0.1, 0.2, 0.3],
            "feature2": [0.4, 0.5, 0.6],
            "label": [1, 0, 1],
        })

        # Call the function under test with max_entities greater than number of entities
        eids = preprocessing.insert_entities_from_dataframe(entity_df, max_entities=5)

        # Assert that the eids returned match the expected values
        assert eids == [1, 2, 3]

        assert len(schema.Entity.objects) == 3

    def test_insert_entities_with_update_feature_values(self):
        feature_df = pd.DataFrame({
            "name": ["feature1", "feature2", "feature3"],
            "type": ["numeric", "categorical", "categorical"],
            "values": [None, ["C", "D"], None],
        })
        preprocessing.insert_features_from_dataframe(feature_df)
        # Create a sample entity dataframe
        entity_df = pd.DataFrame({
            "eid": ["1", "2", "3"],
            "feature1": [0.1, 0.2, 0.3],
            "feature2": ["A", "B", "A"],
            "feature3": ["A", "B", "A"],
        })

        # Insert entities with update_feature_values=True
        preprocessing.insert_entities_from_dataframe(entity_df, update_feature_values=True)

        # Check if the new features exist in the database
        feature_df = schema.Feature.find(as_df_=True)
        expected = {"A", "B", "C", "D"}
        assert len(feature_df["values"][feature_df["name"] == "feature2"].squeeze()) == 4
        assert set(feature_df["values"][feature_df["name"] == "feature2"].squeeze()) == expected

        expected = {"A", "B"}
        assert len(feature_df["values"][feature_df["name"] == "feature3"].squeeze()) == 2
        assert set(feature_df["values"][feature_df["name"] == "feature3"].squeeze()) == expected


class TestInsertTrainingSet:
    def test_valid_eids_and_label_column(self):
        entity_df = pd.DataFrame({
            "eid": [1, 2, 3],
            "feature1": [0.1, 0.2, 0.3],
            "feature2": [0.4, 0.5, 0.6],
            "y": [1, 0, 1],
        })
        preprocessing.insert_entities_from_dataframe(entity_df, label_column="y")

        eids = ["1", "2", "3"]
        result = preprocessing.insert_training_set(eids)
        assert isinstance(result, schema.TrainingSet)
        training_set = schema.TrainingSet.find_one()
        assert_frame_equal(training_set.to_dataframe(), entity_df[["feature1", "feature2", "y"]])

    #  Insert a list of eids with invalid eids, and ensure that an error is raised before inserting
    #  the TrainingSet object.
    def test_invalid_eids(self):
        eids = ["1"]  # No entities in database yet
        with pytest.raises(ValidationError):
            preprocessing.insert_training_set(eids)
        assert len(schema.TrainingSet.objects) == 0

    #  Insert an empty list of eids, and ensure that an error is raised before inserting the
    #  TrainingSet object.
    def test_empty_eids(self):
        eids = []
        with pytest.raises(ValueError):
            preprocessing.insert_training_set(eids)
        assert len(schema.TrainingSet.objects) == 0

    #  Set the TrainingSet to include an entity with no label, and ensure error is raised
    def test_no_label_column(self):
        entity_df = pd.DataFrame({
            "eid": [1, 2, 3],
            "feature1": [0.1, 0.2, 0.3],
            "feature2": [0.4, 0.5, 0.6],
        })
        preprocessing.insert_entities_from_dataframe(entity_df)

        eids = ["1", "2", "3"]
        with pytest.raises(ValidationError):
            preprocessing.insert_training_set(eids)
        assert len(schema.TrainingSet.objects) == 0


class TestInsertModelFromObject:
    #  Insert a RealApp object into the database with default parameters.
    def test_default_parameters(self, models, entities):
        schema.Entity.insert_many(entities)
        result = preprocessing.insert_training_set(["ent1", "ent2", "ent3"])

        real_app = pickle.loads(models[0]["explainer"])
        result = preprocessing.insert_model_from_object(
            real_app,
            model_id="model",
            training_set=result,
        )

        assert isinstance(result, RealApp)

        # Check that the model was inserted in the database
        assert schema.Model.find_one(model_id="model") is not None

    #  Insert a RealApp object into the database with all optional parameters.
    def test_all_optional_parameters(self, models, entities):
        real_app = pickle.loads(models[0]["explainer"])
        model_id = "my_model"
        model_description = "This is my model"
        model_performance = "High accuracy"
        training_df = pd.DataFrame({
            "A": [6],
            "B": [1],
            "C": [3],
            "num_feat": [1],
            "cat_feat": ["value1"],
            "bin_feat": [False],
            "label": [1],
        })
        label_column = "label"
        training_size = 1000

        result = preprocessing.insert_model_from_object(
            real_app,
            model_id=model_id,
            model_description=model_description,
            model_performance=model_performance,
            training_df=training_df,
            label_column=label_column,
            training_size=training_size,
        )

        assert isinstance(result, RealApp)
        assert schema.Model.find_one(model_id=model_id) is not None

    #  Insert a RealApp object into the database with fit_explainers=True and no training data.
    def test_fit_explainers_no_training_data(self, models):
        real_app = pickle.loads(models[0]["explainer"])
        with pytest.raises(ValueError):
            preprocessing.insert_model_from_object(real_app, model_id="model", fit_explainers=True)
